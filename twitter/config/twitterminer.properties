[Twitter]
twitter.searchAPI = http://search.twitter.com/
twitter.apiAccountsFile = ../twitter/data/accounts.txt

# Number of tweets to mine from a user's timeline (max = 3200)
twitter.timelineTweetCount = 195
twitter.concatenationWindow = 25
twitter.minFollowers = 50
twitter.maxFollowers = 9990000
twitter.minFriends = 50
twitter.maxFriends = 9990000
twitter.minTweets = 100
twitter.maxTweets = 9990000
twitter.minEnglishRate = 0.7

[Similarity]
# Between 0 and 1. Towards 0 prioritizes specific topics, towards 1 prioritizes general topics.
similarity.generalityBias = 0.0

# Mining mode options: {NONE, NEW, ALL}.
# NONE: Do not mine if more than 1 tweet already exists (for a static experimentation environment).
# NEW: Collect only new tweets since last mine (i.e. not in DB).
# ALL: re-mine all tweets (only useful if mining was terminated mid-way).
twitter.miningMode = NONE

[Redis]
redis.url = ont.tokuda.cs-private:6379

[DBpedia]
dbpedia.namespace = http://dbpedia.org/resource/
#dbpedia.rdfDirectory = ../twitter/data/DBpedia/
#dbpedia.repositoryDirectory = ../twitter/data/DBpedia/Repository/

[DBpediaSpotlight]
#spotlight.url = spotlight.dbpedia.org
spotlight.defaultURL = ont.tokuda.cs-private:2222
spotlight.baseURL = ont.tokuda.cs-private
spotlight.ports = 2222
#spotlight.url = localhost:2222
spotlight.confidence = 0.0
spotlight.support = 0

[Data]
data.dataDirectory = ../twitter/data/
data.userDirectory = ../twitter/data/users/
data.evaluationDirectory = ../twitter/data/evaluation/
data.outputDirectory = ../twitter/data/output/
data.stopwordsFile = ../twitter/data/slangwords.txt

[SQL]
sql.scriptDirectory = ../twitter/scripts/sql/

[SPARQL]
sparql.scriptDirectory = ../twitter/scripts/sparql/
sparql.prefixFile = ../twitter/scripts/sparql/prefixes.txt

[Pruning]
# Pruning mode options: {NONE, LOW, HIGH, BOTH}
pruning.pruningMode = NONE

# Percentage of total number of occurrence to prune (double %)
pruning.dbpediaLowOccurrencePruningRate = 0.2
pruning.schemaLowOccurrencePruningRate = 0.5
pruning.freebaseLowOccurrencePruningRate = 0.05
pruning.yagoLowOccurrencePruningRate = 0.1
pruning.categoryLowOccurrencePruningRate = 0.005

# Percentage of child classes number / super class to prune (integer %)
pruning.dbpediaHighGeneralityPruningRate = 50
pruning.schemaHighGeneralityPruningRate = 50
pruning.yagoHighGeneralityPruningRate = 100
pruning.categoryHighGeneralityPruningRate = 200
# Top # of categories to consider
pruning.categoryTopK = 10

[IO]
# Query retry time in milliseconds
io.queryRetry = 5000

[Log4j]
log4j.rootLogger = INFO, X
#set the appender named X to be a console appender
log4j.appender.X=org.apache.log4j.ConsoleAppender
#set the layout for the appender X
log4j.appender.X.layout=org.apache.log4j.PatternLayout
log4j.appender.X.layout.conversionPattern=[%5p] %d{hh:mm:ss} (%F:%M:%L) %m%n
log4j.logger.TwitterMinerLogger=ALL, fileAppender
# File based log output
log4j.appender.fileAppender=org.apache.log4j.RollingFileAppender
log4j.appender.fileAppender.File=TwitterMiner.log
log4j.appender.fileAppender.MaxFileSize=5000KB
log4j.appender.fileAppender.Append=false
# Keep one backup file
log4j.appender.fileAppender.MaxBackupIndex=1
log4j.appender.fileAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.fileAppender.layout.ConversionPattern=[%5p] %d{hh:mm:ss} (%F:%M:%L) %m%n
